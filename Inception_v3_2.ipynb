{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_v3_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNEOdbfFo2qP7JxXnWz0Lrm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMAGE20/Image-classification/blob/master/Inception_v3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB4Q2KoU2t0L",
        "colab_type": "text"
      },
      "source": [
        "**파이썬 Inception_v3를 이용한 쯔쯔가무시 등 5종 분류 및 예측**\n",
        "\n",
        "2020.02.20 (목)\n",
        " - 각 클래스당 이미지를 2,000장씩 부풀려 같은 비율로 맞춤.<br>\n",
        " (xy_googlenet_1_save.npy: 2,000장 (224,224) 사용)\n",
        " - 모델은 Inception_v3의 pretrained model 사용.<br>\n",
        " (keras.applications.inception_v3에서 이미 학습된 가중치값을 가져와 학습, 속도가 훨씬 빠름)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SSPfpvx25C0",
        "colab_type": "text"
      },
      "source": [
        "**1. 버전 설정 및 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vn-tAZA23_z",
        "colab_type": "code",
        "outputId": "10465d8d-5ae7-45be-a6b5-08c365d45ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Tensorflow 사용버전 설정\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Tensorflow 버전과 GPU 사용 여부 확인\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS03AR5W29ah",
        "colab_type": "code",
        "outputId": "098070fe-4fbd-4e52-e07e-496f157bdf4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkm-P2qF3ges",
        "colab_type": "text"
      },
      "source": [
        "**2. 클래스 및 모듈 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwgqfQNa3gNr",
        "colab_type": "code",
        "outputId": "254c0e06-039a-4494-a44e-62b3e45afe93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Dropout, GlobalAveragePooling2D, Dense, AveragePooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "\n",
        "from keras.engine.saving import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6lhWcwS5CJU",
        "colab_type": "text"
      },
      "source": [
        "**3. dataset 불러오기 & 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQfMt6uP5Ej6",
        "colab_type": "text"
      },
      "source": [
        "(생략된 부분 - 이미지 부풀리는 과정)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJbLR5aY8et1",
        "colab_type": "code",
        "outputId": "4cb3067a-c581-4a08-c2fe-01100cd37028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### np.save로 저장된 파일 불러오기\n",
        "X_train, X_test, y_train, y_test = np.load('./drive/My Drive/final_project/xy_googlenet_1_save.npy', allow_pickle=True)\n",
        "# xy_googlenet_1_save.npy = 2,000장씩 (224,224,3)\n",
        "\n",
        "# 정규화 시키기\n",
        "X_train = X_train.astype('float16') / 255\n",
        "X_test = X_test.astype('float16') / 255\n",
        "\n",
        "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')   # X_train: (9144, 224, 224, 3), y_train: (9144, 5)\n",
        "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')   # X_test: (2287, 224, 224, 3), y_test: (2287, 5)\n",
        "\n",
        "print(f'X_train: {X_train[0]}, X_test: {X_test[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (9144, 224, 224, 3), y_train: (9144, 5)\n",
            "X_test: (2287, 224, 224, 3), y_test: (2287, 5)\n",
            "X_train: [[[0.886  0.8115 0.745 ]\n",
            "  [0.9097 0.8354 0.7686]\n",
            "  [0.933  0.859  0.792 ]\n",
            "  ...\n",
            "  [0.8237 0.643  0.5527]\n",
            "  [0.8354 0.655  0.5605]\n",
            "  [0.8706 0.6904 0.596 ]]\n",
            "\n",
            " [[0.886  0.8115 0.745 ]\n",
            "  [0.9097 0.8354 0.7686]\n",
            "  [0.933  0.859  0.792 ]\n",
            "  ...\n",
            "  [0.8237 0.643  0.5527]\n",
            "  [0.8354 0.655  0.5605]\n",
            "  [0.8706 0.6904 0.596 ]]\n",
            "\n",
            " [[0.89   0.816  0.749 ]\n",
            "  [0.906  0.8315 0.7646]\n",
            "  [0.9214 0.847  0.7803]\n",
            "  ...\n",
            "  [0.8276 0.647  0.5566]\n",
            "  [0.8354 0.655  0.5605]\n",
            "  [0.8667 0.686  0.5923]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.9453 0.8784 0.816 ]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  ...\n",
            "  [0.89   0.784  0.702 ]\n",
            "  [0.8823 0.784  0.706 ]\n",
            "  [0.8706 0.7725 0.6943]]\n",
            "\n",
            " [[0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  ...\n",
            "  [0.894  0.788  0.706 ]\n",
            "  [0.8823 0.784  0.706 ]\n",
            "  [0.859  0.7607 0.682 ]]\n",
            "\n",
            " [[0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  ...\n",
            "  [0.894  0.788  0.706 ]\n",
            "  [0.8823 0.784  0.706 ]\n",
            "  [0.859  0.7607 0.682 ]]], X_test: [[[0.7803 0.569  0.569 ]\n",
            "  [0.7764 0.565  0.565 ]\n",
            "  [0.7764 0.5566 0.5605]\n",
            "  ...\n",
            "  [0.855  0.6704 0.608 ]\n",
            "  [0.847  0.6626 0.6   ]\n",
            "  [0.8394 0.655  0.5923]]\n",
            "\n",
            " [[0.7803 0.569  0.569 ]\n",
            "  [0.7764 0.565  0.565 ]\n",
            "  [0.7764 0.5566 0.5605]\n",
            "  ...\n",
            "  [0.855  0.6704 0.608 ]\n",
            "  [0.847  0.6626 0.6   ]\n",
            "  [0.8394 0.655  0.5923]]\n",
            "\n",
            " [[0.7803 0.569  0.569 ]\n",
            "  [0.7764 0.565  0.565 ]\n",
            "  [0.7764 0.5566 0.5605]\n",
            "  ...\n",
            "  [0.855  0.6704 0.608 ]\n",
            "  [0.851  0.6665 0.604 ]\n",
            "  [0.847  0.6626 0.6   ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.8394 0.608  0.6157]\n",
            "  [0.8433 0.612  0.6196]\n",
            "  [0.847  0.6157 0.6235]\n",
            "  ...\n",
            "  [0.933  0.6743 0.682 ]\n",
            "  [0.933  0.682  0.686 ]\n",
            "  [0.9453 0.6943 0.698 ]]\n",
            "\n",
            " [[0.859  0.6274 0.6353]\n",
            "  [0.859  0.6274 0.6353]\n",
            "  [0.863  0.6313 0.639 ]\n",
            "  ...\n",
            "  [0.9453 0.686  0.702 ]\n",
            "  [0.9453 0.686  0.702 ]\n",
            "  [0.949  0.6904 0.706 ]]\n",
            "\n",
            " [[0.8706 0.639  0.647 ]\n",
            "  [0.8745 0.643  0.651 ]\n",
            "  [0.8784 0.647  0.655 ]\n",
            "  ...\n",
            "  [0.949  0.686  0.714 ]\n",
            "  [0.949  0.6904 0.706 ]\n",
            "  [0.9453 0.686  0.702 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyH82ZrM81Iv",
        "colab_type": "text"
      },
      "source": [
        "**5. 신경망 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Y7O4Kz80jG",
        "colab_type": "code",
        "outputId": "9f00b757-90a6-442a-8478-e798ba17068c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# pre_trained model 불러오기\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = InceptionV3(include_top=False,\n",
        "                          weights='imagenet',\n",
        "                          input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = Dropout(0.5)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 요약\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 5, 5, 2048)   0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          524800      dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 512)          2048        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            2565        batch_normalization_95[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 24,430,373\n",
            "Trainable params: 24,394,917\n",
            "Non-trainable params: 35,456\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s96E7x6Fcpl",
        "colab_type": "code",
        "outputId": "76db27db-b0f8-451d-8168-f5b6de3b7cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# 컴파일\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK01JUuH9A7c",
        "colab_type": "code",
        "outputId": "ecfc068c-e6da-46a7-a2a8-abe4fe558fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 신경망 모델의 성능 향상이 없는 경우 중간에 epoch을 빨리 중지시키기 위해서\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                            verbose=1,\n",
        "                            patience=10)\n",
        "\n",
        "# 신경망 학습모델 파일로 저장\n",
        "model_dir = \"./drive/My Drive/final_project/\"\n",
        "if not os.path.exists(model_dir):  # model_dir이 없을 경우 폴더 생성\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "model_path = model_dir + '/Inception_v3_2.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# 신경망 학습\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,     # 에폭만큼 파라미터 업데이트\n",
        "                    batch_size=200,  # 전체갯수를 batch_size로 나눈 만큼 반복\n",
        "                    callbacks=[checkpoint, early_stop],\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7315 samples, validate on 1829 samples\n",
            "Epoch 1/50\n",
            "7315/7315 [==============================] - 64s 9ms/step - loss: 0.5299 - acc: 0.7985 - val_loss: 0.9177 - val_acc: 0.7922\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.91767, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 2/50\n",
            "7315/7315 [==============================] - 39s 5ms/step - loss: 0.2057 - acc: 0.9198 - val_loss: 0.4827 - val_acc: 0.8097\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.91767 to 0.48269, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 3/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.1247 - acc: 0.9519 - val_loss: 0.9509 - val_acc: 0.7906\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.48269\n",
            "Epoch 4/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0999 - acc: 0.9662 - val_loss: 0.4765 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.48269 to 0.47654, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 5/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.1013 - acc: 0.9657 - val_loss: 0.6670 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.47654\n",
            "Epoch 6/50\n",
            "7315/7315 [==============================] - 39s 5ms/step - loss: 0.0793 - acc: 0.9736 - val_loss: 1.4559 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.47654\n",
            "Epoch 7/50\n",
            "7315/7315 [==============================] - 39s 5ms/step - loss: 0.0669 - acc: 0.9776 - val_loss: 0.8576 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.47654\n",
            "Epoch 8/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0362 - acc: 0.9867 - val_loss: 0.4622 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.47654 to 0.46223, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 9/50\n",
            "7315/7315 [==============================] - 39s 5ms/step - loss: 0.0472 - acc: 0.9833 - val_loss: 0.6698 - val_acc: 0.8196\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.46223\n",
            "Epoch 10/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0366 - acc: 0.9881 - val_loss: 1.3589 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.46223\n",
            "Epoch 11/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0329 - acc: 0.9907 - val_loss: 0.9440 - val_acc: 0.7687\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.46223\n",
            "Epoch 12/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0494 - acc: 0.9835 - val_loss: 0.5797 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.46223\n",
            "Epoch 13/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0484 - acc: 0.9825 - val_loss: 0.6702 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.46223\n",
            "Epoch 14/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0383 - acc: 0.9881 - val_loss: 0.3313 - val_acc: 0.9032\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.46223 to 0.33128, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 15/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.3526 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.33128\n",
            "Epoch 16/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0292 - acc: 0.9911 - val_loss: 1.2506 - val_acc: 0.7239\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.33128\n",
            "Epoch 17/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0226 - acc: 0.9928 - val_loss: 1.0858 - val_acc: 0.7868\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.33128\n",
            "Epoch 18/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0249 - acc: 0.9928 - val_loss: 0.3636 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.33128\n",
            "Epoch 19/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.3822 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.33128\n",
            "Epoch 20/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.4711 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.33128\n",
            "Epoch 21/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0175 - acc: 0.9949 - val_loss: 0.4855 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.33128\n",
            "Epoch 22/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0146 - acc: 0.9955 - val_loss: 0.6525 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.33128\n",
            "Epoch 23/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0273 - acc: 0.9911 - val_loss: 1.9208 - val_acc: 0.7173\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.33128\n",
            "Epoch 24/50\n",
            "7315/7315 [==============================] - 38s 5ms/step - loss: 0.0256 - acc: 0.9915 - val_loss: 1.1530 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.33128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wguizP5r9kwK",
        "colab_type": "text"
      },
      "source": [
        "**6. 신경망 학습 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-O-bPDK9klL",
        "colab_type": "code",
        "outputId": "4fc027ea-6db0-4feb-f0c9-fc950f7b8905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 테스트 데이터를 사용해서 신경망 모델을 평가\n",
        "# 테스트 데이터의 Loss, Accuracy\n",
        "eval = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {eval[0]}, accuracy: {eval[1]}')\n",
        "### 1\n",
        "# Test loss: 0.922806359721617, accuracy: 0.8117209708250093\n",
        "### 2\n",
        "# Test loss: 0.5639182739725371, accuracy: 0.86226497597709\n",
        "# loss: 0.0298 - acc: 0.9891 - val_loss: 0.6317 - val_acc: 0.8529\n",
        "\n",
        "### 3\n",
        "# Test loss: 0.9771581690646073, accuracy: 0.7901180587484162"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2287/2287 [==============================] - 6s 2ms/step\n",
            "Test loss: 0.9969759741671803, accuracy: 0.8430257980407562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8eynDSC3pNF",
        "colab_type": "code",
        "outputId": "d9e55377-2557-40c9-8042-4ca64ee90af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# 학습 데이터와 테스트 데이터의 Loss 그래프\n",
        "train_loss = history.history['loss']  # history dictionary에 저장된 'loss' 키를 갖는 value들을 가져옴\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "x = range(len(train_loss))\n",
        "plt.plot(x, train_loss, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_loss, marker='.', color='blue', label='Val loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEJCAYAAACOr7BbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd3GQ4aN3s6a",
        "colab_type": "code",
        "outputId": "76573624-7902-4259-a75e-22c9ea58780a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# 학습 데이터, 테스트 데이터의 정확도 그래프\n",
        "train_accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "\n",
        "x = range(len(train_accuracy))\n",
        "plt.plot(x, train_accuracy, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_accuracy, marker='.', color='blue', label='Val loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJiAMwzCMiJiAMAzDMCJiAsIwDMOIyP8DJXN+NrPB+t0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZxU4L_G4N96",
        "colab_type": "text"
      },
      "source": [
        "**7. Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc26dbx431dU",
        "colab_type": "code",
        "outputId": "ac90f94c-d99b-4ef9-bcee-d9f683afac94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "# # 저장한 학습모델 불러옴.\n",
        "# model = load_model('./model/Inception_v3_2.model')\n",
        "\n",
        "categories = [\"df\", \"mel\", \"nv\", \"tsu\", \"vl\"]\n",
        "\n",
        "# confusion matrix & classification report\n",
        "print(y_test)\n",
        "\n",
        "y_true = np.argmax(y_test, axis=1)   # 행 중 가장 큰값의 idx\n",
        "# (one-hot-encoding 되어있으므로 1로 표시된 값을 행에서 가장 큰값으로 출력하여 array로 만듦)\n",
        "print(y_true)\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(y_pred)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "# 세로가 실제클래스, 가로가 예측클래스\n",
        "## 1 \n",
        "# [[ 420  334   44   33    1]\n",
        "#  [   1  860   68    1    0]\n",
        "#  [   1  312  595    2    3]\n",
        "#  [   1   20    2 1018    3]\n",
        "#  [   0   13   18    4  819]]\n",
        "\n",
        "### 2\n",
        "# [[412   5  23   3   2]\n",
        "#  [  4 380  58   9   0]\n",
        "#  [  1  40 393   4   0]\n",
        "#  [  0   0   0 536   0]\n",
        "#  [  0   5   2  26 384]]\n",
        "\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=categories)\n",
        "print(report)\n",
        "## 1\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#           df       0.99      0.50      0.67       832\n",
        "#          mel       0.56      0.92      0.70       930\n",
        "#           nv       0.82      0.65      0.73       913\n",
        "#          tsu       0.96      0.98      0.97      1044\n",
        "#           vl       0.99      0.96      0.97       854\n",
        "\n",
        "#     accuracy                           0.81      4573\n",
        "#    macro avg       0.86      0.80      0.81      4573\n",
        "# weighted avg       0.86      0.81      0.81      4573\n",
        "\n",
        "### 2\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#           df       0.99      0.93      0.96       445\n",
        "#          mel       0.88      0.84      0.86       451\n",
        "#           nv       0.83      0.90      0.86       438\n",
        "#          tsu       0.93      1.00      0.96       536\n",
        "#           vl       0.99      0.92      0.96       417\n",
        "\n",
        "#     accuracy                           0.92      2287\n",
        "#    macro avg       0.92      0.92      0.92      2287\n",
        "# weighted avg       0.92      0.92      0.92      2287\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " ...\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]]\n",
            "[0 3 3 ... 1 1 2]\n",
            "[0 3 3 ... 1 1 2]\n",
            "[[433   0   6   1   5]\n",
            " [ 33 241 170   1   6]\n",
            " [ 56   5 375   0   2]\n",
            " [ 11   5   8 463  49]\n",
            " [  1   0   0   0 416]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          df       0.81      0.97      0.88       445\n",
            "         mel       0.96      0.53      0.69       451\n",
            "          nv       0.67      0.86      0.75       438\n",
            "         tsu       1.00      0.86      0.93       536\n",
            "          vl       0.87      1.00      0.93       417\n",
            "\n",
            "    accuracy                           0.84      2287\n",
            "   macro avg       0.86      0.84      0.84      2287\n",
            "weighted avg       0.87      0.84      0.84      2287\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}